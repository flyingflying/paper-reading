
# 生成问题简介

对于生成问题来说, 一般有两种生成策略: "各个击破" 和 "一步到位"。

"各个击破" 的含义是一个元素一个元素生成。对于文本生成来说, 就是一个 token 一个 token 生成, 每一个 token 是基于在此之前的所有 token 生成的。对于图像生成来说, 就是一个 pixel 一个 pixel 生成。这样的模型被称为 **自回归模型** (autoregressive model)。

"一步到位" 的含义是所有的元素一次性生成。对于文本生成来说, 就是一次性生成所有的 token。对于图像生成来说, 就是所有的 pixel 一起生成。这样的模型被称为 **非自回归模型** (non-autogressive model)。

生成问题有什么特点呢? 那就是很多时候你往左走可以, 往右走也可以, 但是 不左不右 就会出问题。什么意思呢?

举例来说, "李宏毅" 是一个常见的中文名, 在网上比较火的有两个人, 一个是演员, 一个是台大的教授。如果是一个问答模型, 你问: "李宏毅是谁?", 那么模型输出 "李宏毅是演员" 或者 "李宏毅是教授" 都是可以的, 但是如果输出 "李宏毅是演授" 就会让人觉得莫名其妙。

现在的模型都是基于 概率论 的。对于自回归模型而言, 预测 "李宏毅是" 下一个 token 时, "演" 和 "教" 的概率都很高, 我们可以随机选择一个, 比方说 "演"。那么在预测 "演" 的下一个 token 时, 只有 "员" 的概率会很高, "授" 的概率很低, 此时只会选择 "员", 而不会选择 "授"。

但是对于非自回归模型, 预测的结果很可能时在第五个 token 的位置, "演" 和 "教" 的概率都很高; 在第六个 token 的位置, "员" 和 "授" 的概率也都很高。那么此时输出的内容不一定是 "演员" 或者 "教授", 也有可能是 "演授" 这样的词语。从而产生很大的问题。

一直以来, 我对语言模型是有疑问的。文本真的符合序列模型吗? 从这个角度来解释, 似乎也挺合理的。

对于图像生成来说, 也有类似的问题。有时候生成的图片是多张图叠加的结果, 此时表现就是图片很模糊, 或者产生分裂的情况。可以参考 [Adversarial_Video_Generation](https://github.com/dyelax/Adversarial_Video_Generation) 中的例子。

那么自回归模型有什么问题呢? 答案是慢, 巨慢无比。和 CRF 一样, 没有办法并行化计算, 只能一步一步地生成。对于文字生成, 还能够接受, 对于图片生成, 像素点过多, 很难接受。

因此, 文字生成一般是 自回归模型, 图片生成一般是 非自回归模型。而对于语音生成来说, 介于两者之间: 先通过自回归模型生成一个中间产物, 再根据中间产物通过非自回归模型生成语音。

## 图像生成

任务分类:

+ Unconditional Generation
+ Text-to-Image Generation
+ Image-to-Image Translation

更多的可以参考 [paperswithcode](https://paperswithcode.com/area/computer-vision/image-generation)。

方法速览:

+ VAE
+ Flow-based model
+ Diffusion model

GAN 可以当作是一个额外的技巧, 和 VAE, Flow 以及 Diffusion 模型都是可以融合的。

除此之外, 还有像 [image-gpt](https://openai.com/research/image-gpt) 这样的自回归模型。

maskgit

mask-predict 2202.04200

2202.04200
2301.00704

acl: D19-1633

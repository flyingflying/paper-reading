
# CasEE

## 简介

论文的全名是: CasEE: A Joint Learning Framework with Cascade Decoding for Overlapping Event Extraction。发表于 ACL2021, 属于 findings 类型的论文。官方链接如下:

+ [论文链接](https://aclanthology.org/2021.findings-acl.14/)
+ [代码链接](https://github.com/JiaweiSheng/CasEE)

### 问题

在事件抽取中, 经常会有 "实体" 重叠的问题。作者将这个问题分成了三类:

+ 实体在不同的事件中担任 "触发词" 的角色
+ 实体在不同的事件中担任 "论元" 的角色
+ 实体在同一个事件中担任多个 "论元" 角色

本篇论文提出了 CasEE 模型, 可以解决上述问题。

### 限制

需要注意的是, 本模型不能处理 "触发词" 触发的两个事件是同一类型的情况。

举例来说, "**腾讯控股** 分别于 **2021年** 和 **2022年** **减持** 了 **京东** 和 **美团** 的股份。"

这句话中包含了两个事件, 分别是:

+ 触发词: 减持; 事件类型: 股份减持; 论元: 腾讯控股, 2021年, 京东
+ 触发词: 减持; 事件类型: 股份减持; 论元: 腾讯控股, 2022年, 美团

但是识别的结果是:

+ 触发词: 减持; 事件类型: 股份减持; 论元: 腾讯控股, [2021年, 2022年], [京东, 美团]

总结一下, CasEE 并没有完全解决实体重叠的问题。

### 和 PLMEE 模型对比

为了更好地定位 CasEE 模型, 我们将其和 PLMEE 模型进行对比。

CasEE 和 PLMEE 一样, 属于 **管道模型**。

在 PLMEE 模型中, 两个子任务分别是: 触发词检测, 论元检测。
在 CasEE 模型中, 三个子任务分别是: 事件类型预测, 触发词检测 和 论元检测。

PLMEE 模型中不同的子任务使用不同的 BERT 编码器, 并且是分开训练的;
在 CasEE 中, 不同的子任务共享一个 BERT 编码器, 并且它们是一起训练的。

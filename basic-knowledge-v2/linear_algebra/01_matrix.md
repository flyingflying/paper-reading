
# 线性代数知识回顾

[TOC]

## 向量的点乘

在欧几里得空间中, [向量点乘](https://en.wikipedia.org/wiki/Dot_product) 的定义是:

$$
\vec{a} \cdot \vec{b} = ||\vec{a}|| \cdot ||\vec{b}|| \cdot \cos \theta
\tag{1}
$$

其中, $\theta$ 是 $\vec{a}$ 和 $\vec{b}$ 之间的夹角 (较小的角), 取值范围在 0 到 180 度之间。而 $\vec{a} \cdot \cos \theta$ 就是 $\vec{a}$ 在 $\vec{b}$ 上的投影长度。那么就可以得到:

$$
\vec{a} \cdot \vec{b} = \pm ||OP|| \cdot ||OB|| \tag{2}
$$

其中, 点 $O$ 是两个向量的起点, 点 $A$ 和点 $B$ 是 $\vec{a}$ 和 $\vec{b}$ 的终点, 点 $P$ 是点 $A$ 投影到直线 $OB$ 上的点。

理解起来很简单: 两个向量的乘积就是两个向量模长的乘积。但是方向不同的两个数字是不能相乘的, 那么就利用 **投影** 让两者在一条直线上, 同向为正, 反向为负。

我们发现, **点乘** 和 **投影** 之间是强相关的, 这一点非常重要。如果 $\vec{a}$ 和 $\vec{b}$ 是单位向量, 那么点乘的结果就是两个向量夹角的 cos 值。因此很多地方会说, 点乘描述了两个向量之间的相关性。

在坐标系中, 向量的起点就是零点; 在 **直角坐标系** 中, 根据 余弦定理, 我们可以得到: 两个向量点乘的结果是对应坐标相乘再求和。用公式表示如下:

$$
\begin{align*}
     \vec{a} \cdot \vec{b} &= \sum_{i=1}^n a_i b_i \\
     &= a_1 b_1 + a_2 b_2 + \cdots + a_n b_n
\end{align*}
\tag{3}
$$

需要注意的是, 公式 $(3)$ 只在直角坐标系中成立, 在斜坐标系 (非直角坐标系) 中是不成立的。

从公式 $(3)$ 引出了 向量 的另外一个视角: 线性函数。

对于形如 $y = k_1 x_1 + k_2 x_2 + \cdots + k_n x_n$ 这样的过零点的 $n$ 元一次函数, 我们可以写成: $y = \vec{k} \cdot \vec{x}$ 的形式。其中, $\vec{k}$ 是系数向量, $\vec{x}$ 是自变量向量, 两者的维度是 $n$, 点乘的结果是函数值。

我们将一次函数称为线性函数。一元线性函数只能是一条直线, 不能是曲线; 二元线性函数只能是一个平面, 不能是曲面; 更多元的就没有办法想象了, 但是可以类比。那么, $\vec{k}$ 可以看作是关于 $\vec{x}$ 的线性函数。

思考一个问题: 线性函数一定要在直角坐标系中吗? 可以在斜坐标系中吗? 答案是肯定的。举例来说, 在平面斜坐标系中, 如果 $x$ 轴和 $y$ 轴的夹角是 60 度, $y = x$ 这条直线也是可以画出来的, 只是和 $x$ 轴之间的夹角不再是 45 度, 而是 30 度了。

> 接下来说一个鸠占鹊巢 ~~(牛头人)~~ 的故事。按照 向量点乘 原本的定义, 其应该是按照 **投影**, 也就是公式 $(1)$ 来定义的, 只是在 **直角坐标系** 中, 恰好可以用公式 $(3)$ 来表示。
>
> 但是, 公式 $(3)$ 的计算太简单了, 又恰巧可以表示 **线性函数**, 于是很多情况下用公式 $(3)$ 作为 向量点乘 的定义, 也不管在不在 **直角坐标系** 中了。在这种情况下, 建议直接将 点乘 理解成 **线性函数** 就好。
>
> 公式 $(1)$: 是我, 是我先, 明明是我先来的。矢量也好, 力学也好, 还是功率的计算也好。~~(编不下去了 QwQ)~~

在下文中, 如果没有提及, 那么 **向量点乘** 指的都是 **线性函数**, 而 **投影** 才是在直角坐标系中的视角。~~(虽然上面是开玩笑, 但真的是反客为主了)~~

## 向量空间

在线性代数中, **空间** 不单单是 **集合** 的意思, 其必须是一个过 **零点** 完整的维度空间。

比方说, 在 **二维空间** 中, 每一个过零点的直线都是 **一维空间**; 在 **三维空间** 中, 每一个过零点的直线都是 **一维空间**, 每一个过零点的平面都是 **二维空间**。但是, 在 **二维空间** 中, 一个过零点对称的 线段 是不构成空间的! 因为无论怎样, 线段 是不可能构成完成的维度空间的。

那么, 一个向量所在的直线就是一维空间, 无论这个向量的维度是多少。两个不共线的向量可以生成整个二维空间。有了这些概念后, 我们就很容易理解空间之间的映射。

## 矩阵-向量 乘法

$\mathbf{A} \cdot \vec{x} = \vec{b}$ 有两种理解方式:

+ **行视角**: 矩阵 $\mathbf{A}$ 的行向量与 $\vec{x}$ 点乘的结果作为 $\vec{b}$ 中的元素值
+ **列视角**: $\vec{b}$ 是矩阵 $\mathbf{A}$ 的线性组合, 线性组合系数是 $\vec{x}$ 中的元素值

**行视角** 用公式表示如下:

$$
\mathbf{A} \cdot \vec{x} =
\begin{bmatrix}
     \vec{r_1} \\ \vec{r_2} \\ \vec{r_3} \\ \vec{r_4}
\end{bmatrix}
\cdot \vec{x} =
\begin{bmatrix}
     \vec{r_1} \cdot \vec{x} \\
     \vec{r_2} \cdot \vec{x} \\
     \vec{r_3} \cdot \vec{x} \\
     \vec{r_4} \cdot \vec{x}
\end{bmatrix} = \vec{b}
\tag{4}
$$

**列视角** 用公式表示如下:

$$
\begin{align*}
\mathbf{A} \cdot \vec{x} &=
\begin{bmatrix}
     \vec{c_1} & \vec{c_2} & \vec{c_3}
\end{bmatrix}
\cdot
\begin{pmatrix}
     x_1 & x_2 & x_3
\end{pmatrix} \\ &=
x_1 \cdot \vec{c_1} + x_2 \cdot \vec{c_2} + x_3 \cdot \vec{c_3} \\ &=
\vec{b}
\end{align*}
\tag{5}
$$

这些都是根据 矩阵-向量 乘法的定义得到的。矩阵的本质是 向量 的集合, 当我们给 行向量 和 列向量赋予不同的意义时, 矩阵也会有其独特的意义。接下来, 我们一个一个来理解。

## 矩阵是变换

上面说了, $\mathbf{A} \cdot \vec{x} = \vec{b}$ 可以看成是 矩阵 $\mathbf{A}$ 的行向量与 $\vec{x}$ 点乘的结果作为 $\vec{b}$ 中的元素值。这里 **点乘** 的含义是 **线性函数**, 不能理解为 **投影**。那么, 我们可以这样理解 矩阵-向量 的乘法:

$\vec{b}$ 中的元素值是 $\vec{x}$ 经过线性函数 $\vec{r}$ 得到的。$\vec{b}$ 中有多少个元素值值, 就需要多少个线性函数。我们将整个过程称为 **线性变换**, 将矩阵 $\mathbf{A}$ 当作是 $\vec{x}$ 的 **函数**。如果矩阵 $\mathbf{A}$ 是 $m \times n$ 维的, 那么就是将 $n$ 维向量转换成 $m$ 维向量。(在数学领域, 变换和函数是一个意思)

如果矩阵是方阵, 我们可以认为是从空间中的一点映射到另外一点。在二维直角坐标系中, 绕着零点的 **旋转**, 沿坐标轴或者零点的 **翻转**, 还有 **缩放**, **错切** 等等都可以用 **矩阵** 的形式来表示。理解这一点在计算机图形学中非常重要。更高级的就是 **仿射变换** 了。

在很多科普视频中, 会形象化的表示 **线性变换**。在二维空间中, 可以理解为将网格纸以原点为中心进行任意的旋转和缩放。

如果方阵中所有的行向量是线性无关的, 那么函数 $\mathbf{A}$ 的定义域是整个 $n$ 维空间, 值域也是整个 $n$ 维空间, 定义域和值域之间是 **一一对应** 的关系, 此时存在逆矩阵 $\mathbf{A}^{-1}$, 进行反映射。

如果方阵中的行向量是线性相关的, 虽然函数 $\mathbf{A}$ 的定义域不变, 但是值域不在是整个维度空间了。以 2 阶方阵为例, 如果两个行向量线性相关, 那么定义域是整个 2 维空间, 值域是一个过零点的直线。那么, 定义域和值域之间是 **多对一** 的关系, 多个 2 维空间的点映射到直线上的一点。此时就不能进行反映射, 也就是说矩阵 $\mathbf{A}$ 不存在逆矩阵。

如果 $n < m$, 也就是将低维向量转化为高维向量, 举例来说就是二维向量变成三维向量, 函数 $\mathbf{A}$ 的定义域是整个二维空间, 值域是三维空间中的某一个平面, 证明过程如下:

> 我们假设三个行向量中两个是 $\vec{r_1}$ 和 $\vec{r_2}$, 且两者是线性无关的, 那么第三个行向量一定可以写成 $k_1 \cdot \vec{r_1} + k_2 \cdot \vec{r_2}$ 的形式。那么可以得到:
>
> $$ b_1 = \vec{r_1} \cdot \vec{x} $$
>
> $$ b_2 = \vec{r_2} \cdot \vec{x} $$
>
> $$
> \begin{align*}
>    b_3 &= (k_1 \cdot \vec{r_1} + k_2 \cdot \vec{r_2}) \cdot \vec{x} \\
>    &= k_1 \cdot (\vec{r_1} \cdot \vec{x}) + k_2 \cdot (\vec{r_2} \cdot \vec{x}) \\
>    &= k_1 \cdot b_1 + k_2 \cdot b_2
> \end{align*}
> $$
>
> 也就是说, $b_3$ 的值和 $b_1$ 以及 $b_2$ 值之间满足某种线性关系。我们可以认为, 二维空间被映射到 $k_1 \cdot x_1 + k_2 \cdot x_2 - x_3 = 0$ 这个平面上。
>
> 更具体地的例子: 如果矩阵 $\mathbf{A}$ 是:
>
> $$
> \begin{bmatrix}
>      1 & 2 \\ 3 & 4 \\ 4 & 6
> \end{bmatrix}
> $$
>
> 你可以用任意一个二维空间的点, 和矩阵 $\mathbf{A}$ 进行左乘运算, 得到的向量都在 $x_1 + x_2 - x_3 = 0$ 这个平面上。

此时, 函数 $\mathbf{A}$ 定义域和值域之间是 **一对一** 的关系, 不是 **一一对应** 的关系, 因为值域不是整个 $m$ 维空间, 那也没有办法进行 **反映射** (除非限制定义域), 因此也不存在逆矩阵。

如果是 $n > m$, 也就是高维向量转化成低维向量, 这时对应关系是很难想象的。如果所有行向量两两垂直, 我们可以通过 **投影** 的方式来理解, 这个后面再说。但是很显然, 函数 $\mathbf{A}$ 的定义域是整个 $n$ 维空间, 值域是整个 $m$ 维空间, 两者间是 **多对一** 的关系, 自然是不存在逆矩阵的。

## 矩阵是空间

在行视角中, 我们将一个行向量理解为一个 **线性函数**, 那么整个矩阵就是 **线性变换**。

而在列视角中, 我们将所有的列向量当作是空间的 **一组向量**, 那么整个矩阵就可以表示一个 **向量空间**, 因为这个空间中的所有向量都可以写成这组向量 **线性组合** 的形式。

对于公式 $(5)$ 来说, $\vec{b}$ 可以表示为矩阵 $\mathbf{A}$ 列向量的 **线性组合** 的形式, 也就是说, $\vec{b}$ 在矩阵 $\mathbf{A}$ 的列空间中。

如果用 $\mathbf{A} \cdot \vec{x} = \vec{b}$ 来表示线性方程组, 从 **行视角** 可以理解为: 寻找一个 $\vec{x}$, 经过函数 $\mathbf{A}$ 的变换后, 变成 $\vec{b}$。那么从 **列视角** 怎么理解呢?

> 假设 $\vec{b}$ 在矩阵 $\mathbf{A}$ 的列空间中, 寻找列向量线性组合的系数, 来表示 $\vec{b}$。也就是说, 只要 $\vec{b}$ 在矩阵的列空间中时, 方程组就有解, 否则方程组无解。
>
> 如果矩阵 $\mathbf{A}$ 的维度是 $m \times n$, 那么矩阵的列空间是 $n$ 维空间的子空间, 而 $\vec{b}$ 可以是 $n$ 维空间的任意向量, 下面分情况来看:
>
> 如果矩阵 $\mathbf{A}$ 是 2 阶方阵, 那么 $\vec{b}$ 是任意的 2 维向量。此时:
>
> + 如果矩阵的两个列向量是线性无关的, 也就是列空间是整个 2 维空间, 那么 $\vec{b}$ 一定在列空间中, 此时方程一定有解。(唯一解)
> + 如果矩阵的两个列向量是线性相关的, 也就是列空间是一条过零点的直线, 那么只有 $\vec{b}$ 在这条直线上时才有解; 否则无解。 (大概率无解)
>
> 如果矩阵 $\mathbf{A}$ 的列空间由 2 个 3 维向量构成, 也就是说, $\vec{b}$ 是任意的 3 维向量, 列空间是 3 维空间中一个过零点的平面。只有当 $\vec{b}$ 在这个平面上时才有解, 否则无解。(大概率无解)
>
> 如果矩阵 $\mathbf{A}$ 的列空间由 3 个 2 维向量构成, 也就是说, $\vec{b}$ 是任意的 2 维向量。3 个 2 维向量中最多有 2 个向量是线性无关的。假设列空间是整个 2 维空间, 此时必然有解; 假设列空间是一条直线 (3 个向量共线), 如果 $\vec{b}$ 在这条直线上, 则有解, 否则无解。(大概率有解)

如果矩阵 $\mathbf{A}$ 是方阵, 且所有列向量之间是线性无关的, 那么列向量就是空间的一组基。假设矩阵 $\mathbf{A}$ 的列向量是标准坐标系的, $\mathbf{A} \cdot \vec{x}$ 可以理解为将 $\vec{x}$ 从列向量坐标系中转换到标准坐标系中, $\mathbf{A}^{-1} \cdot \vec{b}$ 可以理解为将 $\vec{b}$ 从标准坐标系转换为列向量坐标系中。如果矩阵 $\mathbf{A}$ 的列向量是在斜坐标系中, 也是可以得到类似的结论的。

## 矩阵的四个子空间

如果矩阵 $\mathbf{A}$ 的维度是 $m \times n$ 且秩为 $r$, 那么:

矩阵 $\mathbf{A}$ 的行空间维度和列空间维度都是 $r$, 只是行空间是 $m$ 维空间的 $r$ 维子空间, 列空间是 $n$ 维空间的 $r$ 维子空间。

实际上, 行空间和列空间的联系也仅限于此, 很多人会好奇两者之间的关系, 我们可以感性的理解一下:

如果矩阵 $\mathbf{A}$ 的形式是:

$$
\begin{bmatrix}
    a & b \\
    ka & kb
\end{bmatrix}
$$

我们可以轻易的发现, 两个行向量之间相差 $k$ 倍, 因此是线性相关的, 两个列向量之间相差 $\frac{a}{b}$ 倍, 因此也是线性相关的。那么对于行空间, 我们可以用 $[a, b]$ 这个向量来表示, 对于列空间, 我们可以用 $[a, ka]$ 这个向量来表示。此时, $k$ 的值并不影响矩阵的行空间, 但是却实实在在的影响矩阵的列空间。由此可以看出, 行空间和列空间的关系也仅限于两者的维度是一致的。

更一般地, 如果矩阵 $\mathbf{A}$ 的形式是:

$$
\begin{bmatrix}
    a_1 & a_2 & a_3 \\
    b_1 & b_2 & b_3 \\
    k_1a_1 + k_2b_1 & k_1a_2 + k_2b_2 & k_1a_3 + k_2b_3
\end{bmatrix}
$$

那么此时列向量之间是线性相关的吗? 直观上感觉没有, 但是实际上是的, 如果求解, 可以得到:

$$
\frac{a_2b_3 - a_3b_2}{a_2b_1 - a_1b_2}
\begin{bmatrix}
    a_1 \\ b_1 \\ k_1a_1 + k_2b_1
\end{bmatrix} +
\frac{a_3b_1 - a_1b_3}{a_2b_1 - a_1b_2}
\begin{bmatrix}
    a_2 \\ b_2 \\ k_1a_2 + k_2b_2
\end{bmatrix} =
\begin{bmatrix}
    a_3 \\ b_3 \\ k_1a_3 + k_2b_3
\end{bmatrix}
$$

公式很复杂, 但是如果仔细看, 线性组合系数的分子和分母都有二阶行列式的影子。观察上式, 不难发现, $k_1$ 和 $k_2$ 的值不影响行空间, 但是会实实在在的影响列空间。

实际上, 一个矩阵有四个相关的空间: 行空间, 列空间, 零空间 和 左零空间。它们之间的关系是:

+ 在零空间中的向量, 和矩阵进行左乘操作, 会变成零向量
+ 在左零空间中的向量, 和矩阵进行右乘操作, 会变成零向量
+ 行空间任意一个向量和零空间任意一个向量是垂直的关系
+ 行空间的维度和列空间的维度是一致的, 都是 $r$
+ 零空间的维度是 $m - r$, 左零空间的维度是 $n - r$

对于 $\mathbf{A} \cdot \vec{x}$ 来说, $\vec{x}$ 可以是 $m$ 维空间的任意向量, 但是我们可以将其分解为两个向量, 一个是行空间的向量 $\vec{x}_r$, 一个是零空间的向量 $\vec{x}_n$。其中, $\vec{x}_n$ 被转换成零向量了, $\vec{x}_r$ 被转换成列空间中的向量了。那么, 我们可以将 矩阵-向量 的乘法理解为行空间到列空间的映射。

## 矩阵的逆

我们是如何定义矩阵的逆呢? 首先, 我们定义单位矩阵 $\mathbf{I}$, 其满足 $\mathbf{A} \mathbf{I} = \mathbf{I} \mathbf{A} = \mathbf{A}$。也就是说, 单位矩阵和数字 1 的概念是对应的。

然后, 我们定义矩阵的逆, 其满足 $\mathbf{A}^{-1} \mathbf{A} = \mathbf{A} \mathbf{A}^{-1} = \mathbf{I}$。也就是说, 矩阵的逆和倒数的概念是对应的。

那么, 我们可以进行如下的推导:

$$
\begin{align*}
     \mathbf{A} \cdot \vec{x} &= \vec{b} \\
     \mathbf{A}^{-1} \cdot \mathbf{A} \cdot \vec{x} &= \mathbf{A}^{-1} \cdot \vec{b} \\
     \mathbf{I} \cdot \vec{x} &= \mathbf{A}^{-1} \cdot \vec{b} \\
     \vec{x} &= \mathbf{A}^{-1} \cdot \vec{b}
\end{align*}
$$

对于方程组而言, 如果其有唯一解, 那么这个解就是 $\mathbf{A}^{-1} \cdot \vec{b}$。

对于矩阵 $\mathbf{A}$ 是将 $\vec{x}$ 从列向量坐标系转换到标准坐标系中, 那么 $\mathbf{A}^{-1}$ 就是将 $\vec{b}$ 从标准坐标系转换到列向量坐标系中。

## 矩阵与投影

对于任意坐标系中的一点 $P$, 我们怎么确定其坐标值呢?

过 $P$ 点作 $x$ 轴的平行线, 和 $y$ 轴的交点记为 $Y$, 那么 $OY$ 的长度就是 $y$ 轴上的坐标值; 过 $P$ 点作 $y$ 轴的平行线, 和 $x$ 轴的交点记为 $X$, 那么 $OX$ 的长度就是 $x$ 轴的坐标值。

在直角坐标系中, 作 $x$ 轴的平行线等价于作 $y$ 轴的垂线, 而垂线和 **投影** 可以关联起来。换言之, 如果 $\mathbf{A}$ 的行向量之间是相互垂直的, 那么我们可以得到如下的结论:

$\mathbf{A} \cdot \vec{x}$ 就是将 $\vec{x}$ 投影到矩阵 $\mathbf{A}$ 的每一个行向量 $\vec{r}$ 上。此时我们就可以构建坐标系了。坐标系的基向量满足:

当所有行向量是单位向量时, $\vec{r}$ 就是基向量。更一般的, 每一个轴的基向量是 $\frac{\vec{r}}{||\vec{r}||^2}$ 。理解起来很容易: 当基向量是单位向量, 也就是 $\frac{\vec{r}}{||\vec{r}||}$ 时, 投影长度才是坐标值; 现在点乘的结果是 投影长度 乘以 $\vec{r}$ 的模长, 那基向量改成 单位向量 除以 $\vec{r}$ 的模长, 点乘的结果就是坐标值啦。

如果矩阵 $\mathbf{A}$ 的行向量在标准坐标系中, 那么可以说将点 $\vec{x}$ 从标准坐标系转化成由矩阵 $\mathbf{A}$ 行向量构成的坐标系中。这个过程正好和上面所说的 **列视角** 相反。由此, 我们可以得到结论:

假设方阵 $\mathbf{A}$ 的所有行向量两两之间相互垂直, 也就是空间的一组基, 那么求逆矩阵的过程是: (1) 每一个行向量除以模长的平方; (2) 对矩阵进行转置操作。

如果方阵 $\mathbf{A}$ 可以写成:

$$
\mathbf{A} = \begin{bmatrix}
    r_1 \\ r_2 \\ \vdots \\ r_n
\end{bmatrix}
$$

那么其逆矩阵可以写成:

$$
\mathbf{A}^{-1} = \begin{bmatrix}
    \frac{\vec{r_1}}{||\vec{r_1}||^2} & \frac{\vec{r_2}}{||\vec{r_2}||^2} & \cdots &\frac{\vec{r_n}}{||\vec{r_n}||^2}
\end{bmatrix}
$$

更特殊地, 参考 [问答](https://math.stackexchange.com/questions/52717), 如果矩阵 $\mathbf{A}$ 的所有行向量模长为 1, 且两两垂直, 那么 $\mathbf{A}^{-1} = \mathbf{A}^T$ 。不仅如此, 其列向量的模长也是 1, 且两两垂直。我们将这样的矩阵称为 **标准正交矩阵**。

这一部分的知识要好好理解, 不然看 PCA 算法时会不知所云。

## 矩阵-矩阵 乘法

对于 $\mathbf{A} \cdot \mathbf{B} = \mathbf{C}$, 其有四种理解方式:

首先, 行向量-列向量视角: 将左矩阵 $\mathbf{A}$ 的行向量和右矩阵 $\mathbf{B}$ 的列向量进行点乘, 按照位置依次排序, 得到结果矩阵 $\mathbf{C}$。

其次, 矩阵-列向量视角: 结果矩阵 $\mathbf{C}$ 的每一个列向量是左矩阵 $\mathbf{A}$ 和右矩阵 $\mathbf{B}$ 列向量相乘的结果。进一步, 结果矩阵 $\mathbf{C}$ 的每一个列向量是左矩阵 $\mathbf{A}$ 列向量的线性组合, 其系数是右矩阵 $\mathbf{B}$ 中的列向量。

接着, 行向量-矩阵视角: 结果矩阵 $\mathbf{C}$ 的每一个行向量是左矩阵 $\mathbf{A}$ 行向量和右矩阵 $\mathbf{B}$ 相乘的结果。进一步, 结果矩阵 $\mathbf{C}$ 的每一个行向量是右矩阵 $\mathbf{B}$ 行向量的线性组合, 其系数是左矩阵 $\mathbf{A}$ 中的行向量。

最后, 列向量-行向量视角: 左矩阵 $\mathbf{A}$ 的列向量和右矩阵 $\mathbf{B}$ 的行向量进行 **矩阵乘法**, 得到的所有矩阵相加。用公式表示如下:

$$
\begin{bmatrix} \vec{c_1} & \vec{c_2} & \cdots & \vec{c_k} \end{bmatrix} \cdot
\begin{bmatrix} \vec{r_1} \\ \vec{r_2} \\ \vdots \\ \vec{r_k} \end{bmatrix} =
\sum_{i=1}^{k} \begin{bmatrix}
    c_{i1} r_{i1} & c_{i1} r_{i2} & \cdots & c_{i1} r_{in} \\
    c_{i2} r_{i1} & c_{i2} r_{i2} & \cdots & c_{i2} r_{in} \\
    \vdots & \vdots & \ddots & \vdots \\
    c_{im} r_{i1} & c_{im} r_{i2} & \cdots & c_{im} r_{in} \\
\end{bmatrix}
\tag{6}
$$

除此之外, 还有 block multiplication, 即一个矩阵可以分块相乘。这个在并行化计算中非常重要, 有兴趣的自行搜索。

## 总结

本文洋洋洒洒的写了一大堆。同时, 在写的过程中, 纠正了好几次错误。本来想写一个总结的, 但是估计又要写几百字, 就放弃了。
